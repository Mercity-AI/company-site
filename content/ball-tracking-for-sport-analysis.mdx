---
title: AI Ball Tracking for Sport Analysis
slug: ball-tracking-for-sport-analysis
publishedAt: '2025-05-26'
createdAt: '2024-04-22'
updatedAt: '2025-05-26'
summary: >-
  In this blog we show how you can use AI and ball tracking techniques for sport
  analysis and improve performance of players in games like basketball, soccer,
  football, cricket, etc. We compare the new approaches and the old too.
authors:
  - name: Pranav Patel
category: AI in Sport Analysis
image: >-
  https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c57883a69ca6051b9010_Screenshot-2024-04-23-014538.png
---

<div class="rich-text w-richtext"><p>Accurate ball tracking has long been a holy grail in sports technology, promising to unlock new insights and improvements in athlete performance. It can be used for various tasks, from gathering valuable data to helping referees make decisions, even for predictive analysis. However, developing reliable ball tracking systems has proven to be a complex and challenging task. However, the recent breakthroughs in AI and computer vision space have introduced new models and methods to enhance ball tracking greatly.</p><p>In this article, we'll explore the latest advancements in AI-powered ball tracking, and how they're overcoming these challenges to revolutionize the sports industry.</p><h2 id="what-is-ball-tracking">What is Ball Tracking</h2><p>Ball tracking in sports is simply tracking the ball as it moves around in the field. Along with this, things like collision detection with the bat or racket, speed analysis, and player interaction with the ball are also measured and tracked. These are valuable data points in the sports analysis industry as for most of the games the “ball” itself is at the core. It might be kicking the ball, putting the ball in a basket, or hitting the ball with a bat or a racquet. Balls are involved in one way or another in most of the popular games.</p><p>Ball tracking has become almost a necessary part of most of the games. It just allows the players, regulators, and viewers to extract so much more information from the games. It really enriches the experience and improves the game overall.</p><p>Let’s talk about some of the advantages of using Ball tracking in sports.</p><h3 id="ball-tracking-for-making-better-decisions">Ball tracking for Making Better Decisions</h3><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:767pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4ccd640d668b585a37f_9XmEseyqhwi1khs3mv8ygmcjmp3bjYdETbNTDErADE2HlObV9PbHTmz3_ZEXdFo1Z3SUc1Qs1z5TDR5fGyQb93ekmi0UPdeFyjFj8iMSnnAGgG40irCZARY5pfksCc21vHTL1A8vvciLgVdqNbNKxT0.png"/></div></figure><p>Making judgment decisions is one of the most important parts of any sport, with or without balls. Most of them are straightforward like fours and sixes in Cricket, but in some cases, these can become very difficult, like LBW (Leg before Wicket) and No Ball judgment in Cricket. These edge case scenarios are now handled by “3rd Umpires”, These are the umpires sitting in a room with a lot of video feed coming from all over the field.</p><p>For the 3rd umpires, ball tracking data is essential. When the field umpires cannot make a decision they refer to the 3rd umpires, which then using ball tracking and other sport analysis techniques, make a decision for them. This requires a lot of work and a lot of data processing in real-time.</p><h3 id="ball-tracking-for-improving-player-performance">Ball Tracking for Improving Player Performance</h3><p>Ball tracking has been used by players for a long time now to improve their own performance and to understand the flaws in other people’s playing styles too. Bowlers use it all the time to understand how they are handling the ball and where can they improve further to score the most wickets. Golf players use ball tracking with pose estimation to understand how they should hit the ball and at what angle. Doing all this provides players with extremely granular data and very good feedback by the system, with all this, it’s very to improve and catch mistakes. At this point, this is something every player in the industry uses.</p><h3 id="ball-tracking-for-assisting-coaches">Ball tracking for Assisting Coaches</h3><p>Along with improving individual performances, coaches have started making better teams based upon different metrics gathered through sports analytics systems such as ball speed, spin rate, distance covered while running after hitting the shot, and number of steps taken during the batting stance preparation phase. This allows managers/coaches access detailed insights regarding strengths &amp; weaknesses amongst squad members allowing informed tactical adjustments throughout the season leading ultimately toward success.</p><p>Coaches also analyze opponents’ games thoroughly beforehand so they can devise strategies accordingly against certain styles played previously seen footage recorded via cameras capturing entire match proceedings including replays slow motion clips highlighting key moments helps understand tactics employed by both sides resulting in improved overall quality play. This really helps coaches prepare a better team strategy against any other team.</p><h3 id="ball-tracking-for-fan-engagement">Ball Tracking for Fan Engagement</h3><p>Ball tracking for fan engagement is rather a new phenomenon where providers has been introducing things like “Ball cam”, a special drone or camera that follows the ball specifically. This is new but something viewers love engaging with. Providers also often show the “ball path” and other important visualizations that keep viewers engaged and informed.</p><h2 id="how-does-ball-tracking-work">How does Ball tracking work?</h2><p>There have been many ways Ball tracking is implemented in the actual games. One of them notably being using <a href="https://arxiv.org/abs/1907.03698">TrackNet</a> and <a href="https://arxiv.org/abs/1506.02640">YOLO Networks</a>. These techniques are often paired to provide a good experience and also work well to this date. But we want to introduce newer better models which can track the ball and other objects even better.</p><p>Let’s learn how to build ball tracking pipelines.</p><h3 id="segment-anything-model">Segment Anything Model</h3><p><a href="https://segment-anything.com/">Segment Anything Model</a> by Meta is a rather new and recent model. Segment Anything Model or SAM by Meta is a rather straightforward model. It takes in an image and can take in various types of prompts like masks, boxes, points, and even free-form text. Then the both image and the passed prompt is encoded into a much smaller subspace, these embeddings are then passed into a decoder which outputs a final mask that represents the segmented parts of the image. As you can see in the diagram below:</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:1600pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4ccf3328891acde2836_ivmfLcX8NSuTKxhFx_4PX7cDDN9tk7iJTqcgv3WKbOCNY83Kix8dnwywwKuIU4O_1ki3SzGln2IVXPYV4kVXMIQCo96xw9rffKTIO4oz4iG0jqb0C5banUYs62FMXqB_t5a7TfaMob-k2JEO4_P7IQ4.png"/></div></figure><p>This means that you can pass a normal image like this:</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:1526pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4ccf3328891acde27f3_D-lrdosjr2eWoRl9mVQVnlwaVfQKLwErj7s2OfSz5Y2iya9fGew_Ep_jG3zsySFgc69Gi9uF1w6cgOEZLvMQL0RrUgsq1HQkJumuUYaJRTK8ugGw0mthsG34OGI6bt56QMVLo-5oONZkN-A4ZNGsqa8.png"/></div></figure><p>And segment all the players and extract information from it like this:</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:1529pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4cceabf7815186d0337_kbNcoJ-CJeUMGjd7_qTBLl5TcT90qpUKwfqVwEk-TrK_3tGF9h2IRAnWSLvkIXX7rOxFlxPYF5v9dooP0XjvhIPTIrFvGMFQq5xzEPXaAWn0IaMaqSgemsoQMCvv4r_F4ItfiR_NtlAkyS2HDU4XBNc.png"/></div></figure><p>As you can see the model was able to extract all the details from the image, the players, the pitch, the umpire the hats, helmets, etc. This is very granular data. This data can further be used to analyze a lot of things in the games, and also, track specific players, balls, and whatnot.</p><h3 id="track-anything-model">Track Anything Model</h3><p>The <a href="https://arxiv.org/abs/2304.11968">Track Anything model</a> is an extension of the Segment Anything Model, integrating the <a href="https://arxiv.org/abs/2207.07115">X-Mem architecture</a> with it to allow it to operate over images. Track anything is first used to create a segmentation mask for the object that is desired to be tracked, the mask is then provided to the X-Mem model which is very good in tracking objects over a long-term video.</p><p>X-Mem uses the Atkinson-Shiffrin Memory Model which is similar to how human beings process and store information and memory, the same architecture is then used over consistent frames to track an object through the video. Over the years X-mem has evolved into a much better architecture, <a href="https://arxiv.org/abs/2307.15958">X-Mem++</a> being the latest one. All these techniques can be used to track players, balls, and other elements in a game.</p><p>Here you can see Stephen Curry being tracked across shot changes over a 2 minute video.</p><div class="w-embed"><video controls="">
<source src="https://user-images.githubusercontent.com/30309970/232848349-f5e29e71-2ea4-4529-ac9a-94b9ca1e7055.mp4" type="video/mp4"/>
</video></div><div class="w-embed"></div><p>This same pipeline can be used for any game, like soccer, baseball, basketball, cricket, golf and whatnot.</p><h3 id="latest-updates-sam2-and-edgetam">Latest Updates - SAM2 and EdgeTAM</h3><p>While SAM made great progress in image segmentation, it wasn't designed to handle the fast, unpredictable world of videos. Even though SAM is great for segmenting images, current video segmentation models and datasets still fall short when it comes to “segmenting anything in videos”</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:992pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238c9f4546db5e49f9adaf_AD_4nXdDLGwyVX2YurVKWnZ86FIygfLHTJUqZ5tTvAXscwRWtfmuaWHl6K7ke7eRBy6NX4hicWVBW6cBNq_XvacyJH21kFvR4ZVhLeWplHUyf8X15p8kmi1QXyq-WI2zJbQ_KKgQ2f3dvA.png"/></div></figure><p>That’s where<a href="https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/"> <strong>SAM 2</strong></a> comes in. It builds on SAM by creating a unified model for both image and video segmentation, introducing a streaming architecture with memory attention. This new memory system keeps track of earlier frames and uses that context to improve predictions over time. As a result, SAM 2 can track and segment objects more accurately across movement, occlusion, and lighting changes, even with fewer user inputs.</p><p>When it comes to performance, SAM 2 is a huge upgrade. It delivers better segmentation with 3× fewer interactions, outperforms previous models on standard video benchmarks, and even beats SAM on image tasks while running 6× faster.</p><p>SAM 2 is powerful, but it's too heavy to run efficiently on mobile devices. The main bottleneck is the memory attention blocks added for video processing. To solve this, a lightweight version of SAM2 called<a href="https://yformer.github.io/efficient-track-anything/"><strong> EdgeTAM </strong></a>was introduced.</p><p>EdgeTAM replaces the heavy memory system with a new component called the 2D Spatial Perceiver. This module reads stored video frame data more efficiently using a lightweight transformer. Instead of scanning everything in detail, it uses a fixed set of smart "queries" that focus only on what matters. This keeps it fast without losing accuracy.</p><p>Since video segmentation requires pixel-level precision, EdgeTAM keeps the spatial layout of the memory intact. It organizes the queries into two groups -<strong> global-level</strong> queries that look at the full scene, and <strong>patch-level</strong> queries that focus on small, local areas. This balance helps the model capture both the overall context and fine details.</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:427pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238c9e1aae7e8f537ec3e6_AD_4nXegaFwZzWIUVMMwbxSI9WBwExRAFS_P3sQpwfIOgx08EZnjVxyh-LboOTIaQQ4wAelZoeEQPr6uNOQxz0pjDpaBLR_9MBLQfVZ4njAegN7z21WTOf2PwLhAl1ao-xImLL_hHGOgoA.png"/></div></figure><p>As a result, EdgeTAM achieves 87.7, 70.0, 72.3, and 71.7 J &amp;F on DAVIS 2017, MOSE, SA-V val, and SA-V test, while running at <strong>16 FPS</strong> on iPhone 15 Pro Max.</p><h2 id="state-of-the-art-ball-tracking-models-may-2025">State-of-the-art Ball tracking Models (May-2025)</h2><h3 id="tracknetv3">TrackNetV3</h3><p>Ball tracking has moved from slow, error-prone manual tagging to real-time AI systems that handle speed, clutter, and occlusion with ease. TrackNet was an early deep learning model that used CNNs to detect balls in motion, even in visually noisy sports footage.</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:1600pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238cc018f8720621da1abd_AD_4nXfpav-QWygoPndhCWntEf7X5I3nlGXdmFxit4E_hw3ehjoKjbDCvELUK3HYVrNkh_8aphxVZEunnIiFq6OFw7NcyQwXd-dQvSB9hsXdxEhLueW7OoEIeDqvOKy8ClpeHXgtVKen.png"/></div></figure><p>TrackNetV2 improved on this by using a U-Net architecture. It processed multiple frames and predicted heatmaps, which helped it deal better with motion blur, occlusion, and lighting changes. It achieved an IoU (overlap between original and predicted mask) of 0.82 but still struggled when the ball disappeared mid-play.</p><p><strong>TrackNetV3 </strong>solves this issue with two modules - trajectory prediction and rectification. The prediction module looks at a sequence of frames plus a background image, helping the model ignore static distractions and focus on the moving object. If the shuttle gets occluded or missed, the rectification module kicks in. It studies the trajectory, guesses where the ball likely was, and “repairs” the gap using inpainting (filling in missing positions).</p><p>It also uses mixup augmentation, it mixes different training examples to help the model handle strange lighting, and unpredictable ball movements. As a result, TrackNetV3 reaches 97.51% tracking accuracy, better than TrackNetV2 (94.98%) and much higher than general models like YOLOv7 (53.47%). Its IoU score also improves to 0.91.</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:653pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238cbec06b3667c7a3e8e2_AD_4nXfoyoqG9CrxymQZIPh9nOaMm4hrSGSp6uE4K_Wt6a3HixRdw798g5TmpTe8F-NAcR2x-o-B539VGbFIsZI8eWReZRCTZbRpT7GFg9RcUN_K5B5U-vGa2LklJzPxzk9En9HhyE_WqQ.png"/></div></figure><p>TrackNetV3 doesn’t just detect where the ball is, it can guess where it went, even if it disappears for a moment. That is crucial for live replays, analytics, and broadcast graphics, especially in fast sports like badminton.</p><h3 id="yolov11-sahi-bytetrack">YOLOv11 + SAHI + ByteTrack</h3><p>Tracking small objects in high-resolution sports video is challenging due to their tiny size and fast movement. In 4K footage, objects like shuttlecocks or cricket balls typically appear as just 5 to 15 pixels wide.To track them accurately, we need a system built specifically for small, fast-moving objects. A combination of YOLOv11, SAHI, and ByteTrack addresses this challenge.</p><h4 id="yolov11-sahi">YOLOv11 + SAHI  </h4><p>YOLOv11 is designed to detect very small and low-resolution objects in busy scenes. It uses a technique called dynamic attention, which helps the model focus on the important parts of the image, especially where the small objects are. The model also incorporates special blocks called C3k2, which help combine features from different image sizes. This makes it easier to detect objects that are blurry or only partially visible. </p><p>During training, mixup techniques blend different images together to simulate conditions like poor lighting or fast motion. This improves the model’s performance in real sports videos, where conditions are not always ideal.</p><p>Specialized detectors struggle when small objects are just a few pixels in a large 4K frame. <a href="https://docs.ultralytics.com/guides/sahi-tiled-inference/"><strong>SAHI (Sliced Aided Hyper Inference)</strong></a> solves this by splitting the image into smaller, overlapping sections. In each section, the small object occupies a larger portion of the frame, making it easier to detect. </p><div class="w-embed"><pre>
<code class="language-py">

import supervision as sv
from inference import get_model

# Load small-object-optimized model
model = get_model(model_id="yolov8x-640")
image = cv2.imread(<source_image_path>)

# Slice callback
def callback(image_slice: np.ndarray) -&gt; sv.Detections:
    results = model.infer(image_slice)[0]
    return sv.Detections.from_inference(results)

# Run sliced inference
slicer = sv.InferenceSlicer(callback=callback)
detections = slicer(image)

</source_image_path></code>
</pre></div><h4 id="bytetrack">ByteTrack</h4><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:360pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238cbe82a63063ff4fa676_AD_4nXcDvj6i-67I3gfMt1ad8F3rz6zCGEkkVlRqozTm5NIXT19kqtaqtl1xoOW4MsH0BKm_Dc-00OQiBTHc_ckMiT5Yhjveg-DFtyiEWydx8NoIf1y4C2didrZqUhIPdNSfU_VHn-BAPQ.gif"/></div></figure><p>Once an object is detected, the next step is to track it across multiple frames. In fast sports, objects can quickly disappear behind players or move too fast to track consistently. ByteTrack handles this challenge by keeping even low-confidence detections and trying to match them to previously identified tracks.</p><p>It does this using dual-thresholding, which evaluates both high-confidence and low-confidence predictions. Kalman filtering is used to predict where the object will move when it's temporarily out of sight. The matching algorithm connects detections based on the object’s motion and the overlap between frames.</p><p>This approach improves the continuity of tracking, meaning objects are less likely to be misidentified or lost during occlusions. </p><h3 id="samurai">SAMURAI </h3><div class="w-embed"><video controls="" style="width: 100%; height: auto; max-width: 100%;">
<source src="https://raw.githubusercontent.com/yangchris11/samurai/master/assets/samurai_demo.mp4" type="video/mp4"/>
    Your browser does not support the video tag.
</video></div><p>Meta’s “Segment Anything” Model (SAM) excels at image segmentation but struggles with video object tracking, especially in crowded scenes, fast-moving targets, or when objects briefly disappear. The issue lies in SAM’s memory mechanism, which uses a fixed window to store only the most recent frames without assessing their quality. This leads to error accumulation over time, affecting its tracking accuracy in dynamic video scenarios.</p><p>To overcome these challenges, researchers at the University of Washington built a new model called <a href="https://yangchris11.github.io/samurai/"><strong>SAMURAI </strong></a><strong>(Segment Anything Model Using Robust AI)</strong>. It improves SAM by using motion cues and smarter memory selection. It doesn’t need retraining and works well across a range of tracking tasks.</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:1600pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238e1261225b1bc1b74637_AD_4nXcsAZvOOqFEaYBPdJbkxeTWMPjzX4y8EOa1mTo6dm5L7zsdVwPG41M9N3bIB6CQN7Gi0kGUOi8dGeOY2bqn2UMU32baXr46ph5bJwEG2LCdM_u80I1mFQgoQ9sbkrbGGZ_LBcLPug.png"/></div></figure><p>Key Innovations of SAMURAI:</p><ul role="list"><li><strong>Motion Modeling System</strong></li></ul><p>SAMURAI uses motion cues to predict where objects will move in complex, dynamic scenes. This helps it select the right mask and avoid confusion when objects look similar or overlap, ensuring accurate tracking even in challenging situations.</p><ul role="list"><li><strong>Motion-Aware Memory Selection</strong></li></ul><p>SAMURAI improves SAM’s memory by replacing its fixed-window system with a hybrid scoring approach. It evaluates frames based on three factors:</p><ul role="list"><li>Mask similarity</li><li>Object appearance</li><li>Motion patterns</li></ul><p>Only the most relevant frames are kept in memory, minimizing errors and improving tracking accuracy</p><p>SAMURAI works because of its use of motion and memory. It uses Kalman filters to predict object positions and sizes, helping it pick the right mask from multiple options. It only stores frames that meet certain quality thresholds for mask similarity, ensuring it focuses on the most relevant data. The balance improves tracking accuracy and reliability</p><h2 id="performance-comparison">Performance Comparison</h2><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:923px"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/68238cbf0b5009afd8416c76_AD_4nXd1WATk4wld8CgdSUT83dLgqI8Am7eiEZaEKr0I5nMotAa3XEgtz86hbS8oKsmtzCBvn6Ukapk6gaNHi206vREJb0hPgY-faIUG-cLP1FvIvQvnUBq80xIUaNnl1hAjEFMYxtL7.png"/></div></figure><p><strong>TrackNet V3</strong> is efficient on GPU memory (2.5 GB) but lags behind in speed. It manages around <strong>25 FPS </strong>at<strong> </strong>1080p, but drops to <strong>12 FPS</strong> in multi-camera setups, making it more fit for post-event analysis rather than real-time use.</p><p><strong>YOLO + SAHI + ByteTrack</strong> sits in the middle. Without slicing, it can hit <strong>45 FPS</strong>, but once SAHI tiling is used (for better small object detection), speed drops to <strong>15 FPS</strong>. It's CPU-intensive due to multi-threaded slicing, and latency jumps to <strong>66ms</strong> with full slicing, which can impact live responsiveness.</p><p><strong>Samurai</strong> clearly stands out with the highest FPS across both 1080p and 4K setups, achieving <strong>60 FPS </strong>on<strong> </strong>single-camera 1080p and <strong>22 FPS </strong>across 4K multi-camera feeds, thanks to optimized memory streaming and frame handling. Its latency is also the lowest at just <strong>16ms</strong>, making it suitable for live applications.</p><h2 id="how-to-use-ball-tracking-data">How to use Ball Tracking Data</h2><p>Once you have the ball tracking data along with the player data, then you can do a lot of things from there to generate a ton of analytics. Things like player interaction with the ball, team interaction, what player is best at what area, where the ball goes most, etc. All these very essential metrics become very easy to extract and track once we have the data ready, let's see how we can work with all this data.</p><h3 id="team-analysis">Team Analysis</h3><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:957pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4cc138f15fadc052b7f_1SJQICG6dQwlI3eY45QZAAezXGfv56u6bWYVBUgdFSJIuNOCbHTbZHmyMuoS5nepG5Ku8Dc_TRHa8hR5N9fbv2VdYR0cWfP6QZ8JM_IndN0X2QWGtPu-qF8vhtBAbZ08b_UF7vFuAQpYNaBaDTDT3hE.png"/></div></figure><p>Once the ball tracking data is in, we can measure how teams or specific members of the team interact with the ball at several different incidents. This is rather important for games like Basketball and Soccer, as different members seem to perform differently given the phase of the game and the area of the field. Important metrics like the <strong>Strech Index </strong>and <strong>Team Synchrony</strong> can be extremely useful in these scenarios.</p><p>These metrics help understand how much area a team is using and how well. For example, the stretch index of 3 players might be very tight, and that could explain why they have trouble maneuvering the ball over large areas. Whereas, if the other team’s covered area overlaps with our team’s area, we can understand how they are going to interact and study what are some techniques to secure the ball in those scenarios. All this is very valuable to a manager or a coach. You can read more about these metrics <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2018.02416/full">here</a>.</p><h3 id="individual-analysis">Individual Analysis</h3><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:800pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4cc5a631302b32c9600_qupCBBcZ4MYh6QWnpSJONmgm5EBgEBlyIltqShhVk2N1R3pyl4dvsd0RIAWkC8topMC5Rbv87OdYdtvVSmBxCUkUBmeDqRHSy0U1whGMZmcFYWMEvgqSxRCnpeziZuSkBQnG9CXvY29dWJpMH9FZJCA.png"/></div></figure><p>Individual player analysis is as important as team analysis. Things like the individual path of a player, movement speed of a player, distance from the ball as the game moves on, etc. These are important metrics for specific players. We can also understand how a player is performing in different areas of the field. For example, if a player is not moving much in the defensive area, we can understand that the player is not performing well in that area. This is important for the coach to understand and make decisions on how to improve the player in specific areas or what areas to target them for.</p><p>This data can also be used to pair correct players together. 3 players who have a high stretch index together can be paired together to cover a large area of the field. Players who can run faster can be placed closer to the opponent’s side so that they can quickly move back and forth between defense and offense.</p><h3 id="pose-analysis">Pose Analysis</h3><p>Ball tracking data can be further paired up with pose estimation to refine the technique of the player in games like cricket and golf. These games where you have to hit the ball with great accuracy and precision can benefit greatly from pose analysis. You can see how the position of the body changes during hitting the ball and whether certain positions result in better performance than others. Pose estimations can also detect injuries early on before they become serious problems down the road.</p><figure class="w-richtext-align-center w-richtext-figure-type-image" style="max-width:576pxpx"><div><img alt="" loading="lazy" src="https://blog-cdn.mercity.ai/blog/ball-tracking-for-sport-analysis/6626c4cc0d1f398b61e80a7d_fvDpIiDsgkXNHidWABkLNBEwCUtQbAEbWk2TTrhI-Llscs90koRYmGyEZ74fY9m4BJ2qqNFju1PWkiEhlwJCdogNI_9q4DDC3zhN8-oG_tMZpt8Z6gJyR1WAPqyumsaXuugUZzJl5LnOqbm5n_FtFno.png"/></div></figure><p>As you can see in the image, pose estimation in golf can be helpful. Tracking where the ball goes, when hit a certain way, and when the pose is in a certain way. Poses can also be compared with other better players to get an idea of what the player is doing wrong and where the improvement is needed. This same technique can be used for various other things like exercise and posture analysis if needed.</p><h2 id="traditional-methods-vs-track-anything-model">Traditional methods vs Track Anything Model</h2><p>As mentioned before, traditionally, networks like Tracknet have been used for this application. But even Tracknet has its issues.</p><h3 id="performance-issues">Performance Issues</h3><p>Tracknet, being a single architecture, can make mistakes. Tracknet was mainly developed for tracking shuttle cocks during tennis matches, performance across other domains can be very degraded unless finetuned properly. It is seen that smaller faster moving objects, like a ball in cricket, can be problematic for Tracknet to track. However, techniques that build upon Tracknet like <a href="https://arxiv.org/abs/2211.09791">MOTRv2</a> seem to show much better performance. These are not single network architectures but rather pipelines that use the network for the core tracking task.</p><p>SAM, on the other hand, is highly performant in most of the out-of-domain tasks, and when combined with other architectures like X-Mem and X-Mem++, the tracking capabilities are simply SOTA. Similar to Tracknet, pipelines built with SAM might also require some finetuning but performance gains are much greater compared to Tracknet.</p><h3 id="computation-cost-and-inference-time">Computation Cost and Inference Time</h3><p>Another big issue with TrackNet and its dependent pipelines is that it is computationally very heavy as it is mostly a single convolution network, mostly. TrackNetV2’s performance is around <strong>31.8 FPS.</strong> Whereas the Track Anything Model paired with X-Mem++ can do <strong>39 FPS.</strong> And much more if a smaller version of the model is finetuned for a specific use case.</p><p>In production, it is often the case that not all the frames are processed, most are clumped together and a Kalman filter is used with it to track the ball in all the frames altogether</p><h2 id="want-to-build-ball-tracking-pipelines-for-sports">Want to Build Ball Tracking Pipelines for Sports?</h2><p>If you are looking to build ball-tracking pipelines and sports analysis applications, please <a href="https://www.mercity.ai/contacts">reach out to us</a>. We have worked with many computer vision pipelines and have integrated them into already existing systems. Reach out to us to build such pipelines or just to chat. Would love to chat!</p></div>
